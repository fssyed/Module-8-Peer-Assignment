---
title: "Practical Machine Learning Assignment"
author: "Faraz Syed"
date: "August 1, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Practical Machine Learning: Prediction Assignment

This assignment will use data from an experiment which used motion trackers to track how participants performed Unilateral Biceps Curls 5 different ways (A,B,C,D,E) with 'A' being the correct specified way. 

This assignement will use the data produced by the sensors to train a random forest model for the 'classe' dependent variable. The model will then use to test data to predict which set of movements was performed correctly. We will partition the data to check for the model's initial accurcy and selection of independent variables. 

Our task is train the model using the training data set and predict which of the 5 different ways the exercise was performed.

## Getting Data
The data was sourced from the Groupware website (link below in R code)

```{r eval=FALSE}
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "./data/8_training.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "./data/8_test.csv")

```

```{r}
training = read.table("C:/Users/farsyed/Documents/R/Working Dir/data/8_training.csv", header=TRUE, sep=",", na.strings=c("NA", "#DIV/0!"))
test = read.table("C:/Users/farsyed/Documents/R/Working Dir/data/8_test.csv", header=TRUE, sep=",", na.strings=c("NA", "#DIV/0!"))
```

Exploring this data we notice that there are a lot of NA's and columns that will not be used. We want to find the the variables that we will use to predict. The assignment refers to "accelerometers on the belt, forearm, arm, and dumbell". We will now clean the data by removing columns with NA and keeping columns referencing variables with belt, forearm, arm and dumbell. 

```{r}
population = grep("_belt|_arm|_dumbbell|_forearm", names(training))
training2 = training[,c(population,160)]

na.data = is.na(training2)
NAcols=which(colSums(na.data) > 19000)
training2 = training2[,-NAcols]
```
A distribution of the classe variable in the training set - majority of movements seem to be performed correctly :) 

```{r}
barplot(table(training2$classe), ylab="Frequency", xlab=deparse(training2$classe), main="Frequency of Classe - Training")
```

We are left with a data set which now has 53 indpendent variables which can be used to determine the exercise class. We now test the variables for the variances amongst them.
 

## Building the Model with Random Forest using cross validation with the testing data set

we will partition the data 75%/25% for the cross validation and check the results for the out of sample accuracy. 

```{r}
library(caret)
library(randomForest)
set.seed(2018)

sample.train = createDataPartition(y=training2$classe, p=0.75, list=FALSE)
training3 = training2[sample.train,]
testing = training2[-sample.train,]
```

## Training the Model 

```{r}
time1=proc.time()
randForest = randomForest(classe~., data=training3, ntree=500)
```

## Applying the Model to the partitioned Testing data and checking for out of sample accuracy

```{r}
prediction.test = predict(randForest, newdata=testing)
confusionMatrix(prediction.test, testing$classe)
```

The diagonal of the matrix shows the correct predictions in the training, and the off-diagonals represent the incorrect preditions. This model has a high Out of Sample accuracy rate of 99.53%. This should be a good predictor to use on the test data. 

## Applying the Model to the original 20 case test data

First we get clean the test data to only keep the relevant columns.

```{r}
population = grep("_belt|_arm|_dumbbell|_forearm", names(test))
length(population)
test2 = test[,c(population,160)]

na.data = is.na(test2)
NAcols=which(colSums(na.data) > 19)
test3 = test2[,-NAcols]
```

Now we apply the model to the testing data set for our prediction. Results were correctly identified in the quiz 20/20. 

```{r}
prediction.final = predict(randForest, newdata=test3)
```
